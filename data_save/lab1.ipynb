{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6f6fa19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "par_dir = os.path.abspath(os.path.join(os.getcwd(),os.pardir))\n",
    "os.chdir(par_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21b9e355",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "x_data = np.load('./data/metal.npy')\n",
    "c_data = np.load('./data/pre_re_fin.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e150171",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.0e+00, 7.0e+02, 5.0e+00, ..., 4.0e+00, 6.0e+01, 2.1e+01],\n",
       "       [4.0e+00, 7.0e+02, 5.0e+00, ..., 4.0e+00, 6.0e+01, 3.9e+01],\n",
       "       [4.0e+00, 7.0e+02, 5.0e+00, ..., 4.0e+00, 6.0e+01, 4.5e+01],\n",
       "       ...,\n",
       "       [5.0e+00, 3.0e+02, 6.0e+00, ..., 5.0e-01, 1.2e+02, 9.5e+01],\n",
       "       [5.0e+00, 3.0e+02, 6.0e+00, ..., 5.0e-01, 1.2e+02, 9.7e+01],\n",
       "       [5.0e+00, 3.0e+02, 6.0e+00, ..., 5.0e-01, 1.2e+02, 9.8e+01]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6319fdb8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m x_train,x_test,c_train,c_test = train_test_split(\u001b[43mx_data\u001b[49m,c_data, random_state = \u001b[32m22\u001b[39m,test_size = \u001b[32m0.4\u001b[39m)\n\u001b[32m      3\u001b[39m x_val,x_test,c_val,c_test = train_test_split(x_test,c_test,random_state = \u001b[32m22\u001b[39m, test_size = \u001b[32m0.5\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MinMaxScaler\n",
      "\u001b[31mNameError\u001b[39m: name 'x_data' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,c_train,c_test = train_test_split(x_data,c_data, random_state = 22,test_size = 0.4)\n",
    "x_val,x_test,c_val,c_test = train_test_split(x_test,c_test,random_state = 22, test_size = 0.5)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "x_scaler = MinMaxScaler()\n",
    "c_scaler = MinMaxScaler()\n",
    "# s_scaler = StandardScaler()\n",
    "x_train = x_scaler.fit_transform(x_train)\n",
    "c_train = c_scaler.fit_transform(c_train)\n",
    "x_val,x_test = [x_scaler.transform(x) for x in [x_val,x_test]]\n",
    "c_val,c_test = [c_scaler.transform(c) for c in [c_val,c_test]]\n",
    "# import joblib \n",
    "joblib.dump(x_scaler,'./torch_1/min_x_scaler.pkl')\n",
    "joblib.dump(c_scaler,'./torch_1/min_pre_re_scaler.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "428b5c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "x_train,x_val,x_test = [torch.tensor(x, dtype = torch.float32) for x in [x_train,x_val,x_test]]\n",
    "c_train,c_val,c_test = [torch.tensor(c, dtype = torch.float32) for c in [c_train,c_val,c_test]]\n",
    "from torch.utils.data import TensorDataset,DataLoader\n",
    "train_data = [x_train,x_train, c_train]\n",
    "val_data = [x_val,x_val, c_val]\n",
    "test_data = [x_test,x_test, c_test]\n",
    "train_data = TensorDataset(*train_data)\n",
    "val_data = TensorDataset(*val_data)\n",
    "test_data = TensorDataset(*test_data)\n",
    "datas = [train_data,val_data,test_data]\n",
    "train_loader,val_loader,test_loader = [DataLoader(x,batch_size = 64,shuffle=False) for x in datas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa17c37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs('torch',exist_ok = True)\n",
    "torch.save(train_loader,\"torch_1/pre_retrain_loader_min.pt\")\n",
    "torch.save(val_loader,\"torch_1/pre_reval_loader_min.pt\")\n",
    "torch.save(test_loader,\"torch_1/pre_retest_loader_min.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
